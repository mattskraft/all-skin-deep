{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook 01 – Data Exploration\n",
    "\n",
    "This notebook provides a first look at the [HAM10000](https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000) dataset.\n",
    "\n",
    "We’ll explore:\n",
    "- Dataset structure and image counts\n",
    "- Class distributions\n",
    "- Basic quality checks and metadata inspection\n",
    "\n",
    "> **Note**: This notebook assumes that the dataset has been downloaded and placed in the following directory:\n",
    ">\n",
    "> ```\n",
    "> data/raw/HAM10000/\n",
    "> ├── HAM10000_metadata.csv\n",
    "> ├── images/ISIC_0024306.jpg\n",
    "> └── images/ISIC_0024307.jpg\n",
    "> ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Project paths\n",
    "PROJECT_DIR = Path.cwd().parents[0]\n",
    "DATA_RAW = PROJECT_DIR / \"data\" / \"raw\" / \"HAM10000\"\n",
    "IMAGE_DIR = DATA_RAW / \"images\"\n",
    "\n",
    "# Data set location check\n",
    "assert (DATA_RAW / \"HAM10000_metadata.csv\").exists() \\\n",
    "   and (IMAGE_DIR / \"ISIC_0024306.jpg\").exists(), \"Metadata or image files not found. Please check dataset location.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(DATA_RAW / \"HAM10000_metadata.csv\")\n",
    "print(f\"Metadata shape: {metadata.shape}\")\n",
    "metadata.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first glance at the metadata already shows a problem with the dataset: There are duplicate images of the same lesion! Let's deal with that in a moment and have a look at the class distribution first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Distribution\n",
    "\n",
    "Let’s examine how many samples exist for each diagnosis category.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Load data and map labels\n",
    "metadata = pd.read_csv(DATA_RAW / \"HAM10000_metadata.csv\")\n",
    "dx_mapping = {\n",
    "    'nv': 'Melanocytic nevi', 'mel': 'Melanoma', \n",
    "    'bkl': 'Benign keratosis-like lesions', 'bcc': 'Basal cell carcinoma',\n",
    "    'akiec': 'Actinic keratoses', 'vasc': 'Vascular lesions', \n",
    "    'df': 'Dermatofibroma'\n",
    "}\n",
    "metadata[\"dx_full\"] = metadata[\"dx\"].map(dx_mapping)\n",
    "\n",
    "# Get class counts and representative images (just the first one in the table)\n",
    "counts = metadata[\"dx_full\"].value_counts()\n",
    "representatives = metadata.groupby(\"dx_full\").first().reset_index()\n",
    "\n",
    "# Define colors for each category\n",
    "# Melanoma: red, other malignant (basal cell carcinoma, actinic keratoses): orange, benign: green\n",
    "colors = []\n",
    "for category in counts.index:\n",
    "    if category == 'Melanoma':\n",
    "        colors.append('red')\n",
    "    elif category in ['Basal cell carcinoma', 'Actinic keratoses']:\n",
    "        colors.append('orange')\n",
    "    else:\n",
    "        colors.append('green')\n",
    "\n",
    "# Create figure with two columns\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[1, 5], wspace=0.05)\n",
    "ax_img = fig.add_subplot(gs[0])\n",
    "ax_img.axis(\"off\")\n",
    "ax_bar = fig.add_subplot(gs[1], sharey=ax_img)\n",
    "\n",
    "# Create bar plot with custom colors\n",
    "sns.barplot(y=counts.index,\n",
    "            x=counts.values,\n",
    "            ax=ax_bar,\n",
    "            palette=colors,\n",
    "            errorbar=None)\n",
    "ax_bar.set(title=\"Number of Images per Diagnosis\", xlabel=\"Count\", ylabel=\"\")\n",
    "ax_bar.set_xlim(0, counts.max() + 1000)\n",
    "\n",
    "# Add count labels\n",
    "for i, value in enumerate(counts):\n",
    "    ax_bar.text(value + 100, i, str(value), va='center')\n",
    "\n",
    "# Add representative images\n",
    "for i, (_, row) in enumerate(representatives.iterrows()):\n",
    "    try:\n",
    "        img = Image.open(IMAGE_DIR / f\"{row['image_id']}.jpg\").convert(\"RGB\").resize((64, 64))\n",
    "        imagebox = OffsetImage(img, zoom=1)\n",
    "        ab = AnnotationBbox(imagebox, (0.5, i), frameon=False, box_alignment=(0.5, 0.5))\n",
    "        ax_img.add_artist(ab)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Image not found: {row['image_id']}.jpg\")\n",
    "\n",
    "plt.subplots_adjust(left=0.05, right=0.98, top=0.95, bottom=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the dataset is highly unbalanced. This has important implications for training as it is likely to result in problems if not handled well. To deal with this, use both class weights in the model, as well as class multipliers during data augementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Count occurrences of each lesion_id\n",
    "lesion_counts = metadata['lesion_id'].value_counts()\n",
    "\n",
    "# Create a Series counting how many lesions have 1, 2, 3, etc. images\n",
    "duplicate_distribution = lesion_counts.value_counts().sort_index()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=duplicate_distribution.index, y=duplicate_distribution.values)\n",
    "plt.xlabel('Number of Images per Lesion')\n",
    "plt.ylabel('Count of Lesions')\n",
    "plt.title('Distribution of Images per Unique Lesion')\n",
    "\n",
    "# Add count labels on top of bars\n",
    "for i, count in enumerate(duplicate_distribution.values):\n",
    "    plt.text(i, count + 50, str(count), ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So of the 10015 images, about half are of unique lesions, while the rest have at least one duplicate image. Let's look at how lesion duplicates are distributed across classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to check the distribution of duplicate lesions across dx classes\n",
    "\n",
    "\n",
    "# Step 1: Find lesion_ids that have duplicates (more than one image)\n",
    "duplicate_lesion_ids = metadata['lesion_id'].value_counts()\n",
    "duplicate_lesion_ids = duplicate_lesion_ids[duplicate_lesion_ids > 1].index\n",
    "\n",
    "# Step 2: Subset df to only those lesions\n",
    "df_duplicates = metadata[metadata['lesion_id'].isin(duplicate_lesion_ids)]\n",
    "\n",
    "# Step 3: Count how many duplicate lesions appear in each dx class\n",
    "duplicates_per_class = df_duplicates.drop_duplicates('lesion_id')['dx'].value_counts().sort_index()\n",
    "\n",
    "# Step 4: Count total lesions per class (for normalization)\n",
    "total_lesions_per_class = metadata.drop_duplicates('lesion_id')['dx'].value_counts().sort_index()\n",
    "\n",
    "# Step 5: Calculate proportion of lesions with duplicates per class\n",
    "proportion_with_duplicates = (duplicates_per_class / total_lesions_per_class).sort_index()\n",
    "\n",
    "# Show results\n",
    "results_df = pd.DataFrame({\n",
    "    'Total Lesions': total_lesions_per_class,\n",
    "    'Duplicate Lesions': duplicates_per_class,\n",
    "    'Proportion with Duplicates': proportion_with_duplicates\n",
    "}).fillna(0)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, there doesn't seem to be a a large disparity between classes. Let's have a look at some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "def plot_duplicate_lesions(df, image_dir, num_to_show=3, seed=None):\n",
    "    \"\"\"\n",
    "    Plot multiple images of the same lesion to visualize duplicates.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Dataframe containing image metadata with 'lesion_id' and 'filename' columns\n",
    "    image_dir : str or Path\n",
    "        Directory containing the images\n",
    "    num_to_show : int\n",
    "        Number of different lesions to display\n",
    "    seed : int, optional\n",
    "        Random seed for reproducibility\n",
    "    \"\"\"\n",
    "    image_dir = Path(image_dir)\n",
    "    \n",
    "    # Set random seed if provided\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "\n",
    "    # Find lesion_ids with duplicates\n",
    "    lesion_counts = df['lesion_id'].value_counts()\n",
    "    duplicate_ids = lesion_counts[lesion_counts > 1].index.tolist()\n",
    "    \n",
    "    if not duplicate_ids:\n",
    "        print(\"No duplicate lesions found in the dataset.\")\n",
    "        return\n",
    "    \n",
    "    # Randomly sample lesion_ids\n",
    "    selected_ids = random.sample(duplicate_ids, min(num_to_show, len(duplicate_ids)))\n",
    "    \n",
    "    # Plot each selected lesion's images horizontally\n",
    "    for lesion_id in selected_ids:\n",
    "        lesion_df = df[df[\"lesion_id\"] == lesion_id]\n",
    "        \n",
    "        # Try-except block to handle potential file loading issues\n",
    "        try:\n",
    "            fig, axes = plt.subplots(1, len(lesion_df), figsize=(3 * len(lesion_df), 3))\n",
    "            \n",
    "            # Ensure axes is always iterable\n",
    "            if len(lesion_df) == 1:\n",
    "                axes = [axes]\n",
    "            \n",
    "            fig.suptitle(f\"Lesion ID: {lesion_id} ({len(lesion_df)} images)\", fontsize=14)\n",
    "            \n",
    "            for i, (_, row) in enumerate(lesion_df.iterrows()):\n",
    "                img = Image.open(image_dir / row[\"filename\"])\n",
    "                axes[i].imshow(img)\n",
    "                axes[i].set_title(f\"Diagnosis: {row.get('dx_full', row.get('dx', 'Unknown'))}\", fontsize=9)\n",
    "                axes[i].set_xlabel(f\"ID: {row['image_id']}\", fontsize=8)\n",
    "                axes[i].axis(\"off\")\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error displaying lesion ID {lesion_id}: {e}\")\n",
    "\n",
    "# Usage\n",
    "plot_duplicate_lesions(metadata, IMAGE_DIR, num_to_show=3, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it is possible that duplicate images of single lesions where taken with a certain time lag (e.g. at different visits at the dermatologist), they are clearly too much alike and would result in data leakage during training and testing. Thus, we need to get rid of duplicates from now on. For simplicity, we will keep the first occurence of a lesion in an image and remove all others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove lesion duplicates from dataset and save new csv file\n",
    "metadata = pd.read_csv(DATA_RAW / \"HAM10000_metadata.csv\")\n",
    "# Drop duplicates by keeping the first image per lesion_id\n",
    "df_unique_lesions = metadata.drop_duplicates(subset=\"lesion_id\", keep=\"first\")\n",
    "# Save to CSV file\n",
    "df_unique_lesions.to_csv(DATA_RAW / \"HAM10000_metadata_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final count of images to be used: {df_unique_lesions.shape[0]}\")\n",
    "print(\"Final distribution of images across classes:\")\n",
    "df_unique_lesions['dx'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
